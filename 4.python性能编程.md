## 1.线程

### 线程方法

通过实例threading.Thread创建线程

```python
import threading
import time

def task_threading(counter):
    print("线程名称：{}===参数：{}===开始时间：{}".format(
        threading.current_thread().name,
        counter,
        time.strftime("%Y-%m-%d %H:%M:%S")
    ))

    num=counter
    while num:
        time.sleep(3)
        num-=1

    print("线程名称：{}===参数：{}===结束时间：{}".format(
        threading.current_thread().name,
        counter,
        time.strftime("%Y-%m-%d %H:%M:%S")
    ))

if __name__ == '__main__':
    print(f"主线程开始时间：{time.strftime('%Y-%m-%d %H:%M:%S')}")

    #使用Thread() 创建线程
    t1=threading.Thread(target=task_threading,args=(3,))
    t2 = threading.Thread(target=task_threading, args=(2,))
    t3 = threading.Thread(target=task_threading, args=(1,))

    #使用start启动线程
    t1.start()
    t2.start()
    t3.start()

    #join 主线程阻塞等待子线程
    t1.join()
    t2.join()
    t3.join()
    print(f"主线程结束时间：{time.strftime('%Y-%m-%d %H:%M:%S')}")
```

### 继承Thread类

通过继承Thread类，在子类重写run()和init()方法

```python
import threading
import time

class MyThread(threading.Thread):
  
    def __init__(self,counter):
        super(MyThread,self).__init__()
        self.counter=counter

    def run(self) -> None:
        print(f"线程名称:{threading.current_thread().name} 参数：{self.counter} 开始时间：{time.strftime('%Y-%m-%d %H:%M:%S')}")
        counter=self.counter
        while counter:
            time.sleep(3)
            counter-=1
        print(f"线程名称:{threading.current_thread().name} 参数：{self.counter} 结束时间：{time.strftime('%Y-%m-%d %H:%M:%S')}")



if __name__ == '__main__':

    print(f"主线程开始时间：{time.strftime('%Y-%m-%d %H:%M:%S')}")
    t1 = MyThread(3)
    t2=MyThread(2)
    t3=MyThread(1)

    t1.start()
    t2.start()
    t3.start()

    t1.join()
    t2.join()
    t3.join()
    print(f"主线程结束时间：{time.strftime('%Y-%m-%d %H:%M:%S')}")
```

### 线程同步

#### Lock(互斥锁)

保护共享资源，防止多个线程同时访问导致数据竞争和不一致的问题。

互斥锁是一种同步原语，用于防止多个线程同时访问共享资源，从而避免数据竞争和不一致的问题。

创建锁对象：

```python3
lock=threading.Lock()
```

获取锁：

在需要保护的代码块前调用 `acquire()`方法获取锁。如果锁已经被其他线程持有，则当前线程会被阻塞，直到锁被释放。

```python3
lock.acquire()
```

释放锁：

在需要保护的代码块后调用 `release()`方法释放锁。

```python3
lock.release()
```

为了确保锁一定会被释放，可以使用 `with`语句自动获取和释放锁。

```python
with lock:
    # 需要保护的代码块
    pass
```

案例:

```python
import threading

# 共享资源
counter = 0
# 创建一个Lock对象
lock = threading.Lock()

def worker():
    global counter
    for _ in range(100000):
        # 获取锁
        lock.acquire()
        try:
            counter += 1
        finally:
            # 释放锁
            lock.release()

# 创建10个线程
threads = [threading.Thread(target=worker) for _ in range(10)]

# 启动线程
for t in threads:
    t.start()

# 等待线程执行完毕
for t in threads:
    t.join()

print("Counter:", counter)
```

#### RLock（可重入）

是一种特殊互斥锁，允许一个线程多次获取同一个锁，而且不会导致死锁。

创建锁对象

```text
lock=threading.RLock()
```

获取锁

```text
lock.acquire()
```

释放锁

```text
lock.release()
```

为了确保锁一定会被释放，可以使用 `with`语句自动获取和释放锁。

```python
with rlock:
# 需要保护的代码块
pass
```

下面是一个使用 `RLock`的示例：

```python
import threading

class Counter:
    def __init__(self):
        self.value = 0
        self.rlock = threading.RLock()

    def increment(self):
        with self.rlock:
            self.value += 1

    def decrement(self):
        with self.rlock:
            self.value -= 1

    def get_value(self):
        with self.rlock:
            return self.value

counter = Counter()

def worker():
    for _ in range(100000):
        counter.increment()
        counter.decrement()

# 创建10个线程
threads = [threading.Thread(target=worker) for _ in range(10)]

# 启动线程
for t in threads:
    t.start()

# 等待线程执行完毕
for t in threads:
    t.join()

print("Counter:", counter.get_value())
```

#### Semaphore(信号量)

保持最大同时访问量，控制多个进程或线程对共享资源访问的的同步原语。

信号量的值表示可以同时访问共享资源的线程或进程的数量。当一个线程或进程请求信号量时，信号量的值会减1；当线程或进程释放信号量时，信号量的值会加1。如果信号量的值为0，表示没有可用的资源，请求信号量的线程或进程会被阻塞，直到有其他线程或进程释放信号量。

创建信号量对象

```python3
#参数3，表示允许3个线程进入同步代码块
semaphore=threading.BoundedSemaphore(3)
```

获取锁

```python3
semaphore.acquire()
```

释放锁

```python3
semaphore.release()
```

案例：

```python
import threading
import time

# 共享资源
resources = [None] * 3
# 创建一个信号量对象，初始值为3
semaphore = threading.Semaphore(3)

def worker(index):
    # 请求信号量
    semaphore.acquire()
    print("Worker %d is using resource %d" % (index, index % 3))
    resources[index % 3] = "Worker %d" % index
    time.sleep(1)
    resources[index % 3] = None
    print("Worker %d has released resource %d" % (index, index % 3))
    # 释放信号量
    semaphore.release()

# 创建10个线程
threads = [threading.Thread(target=worker, args=(i,)) for i in range(10)]

# 启动线程
for t in threads:
    t.start()

# 等待线程执行完毕
for t in threads:
    t.join()

print("Resources:", resources)
```

### 线程的挂起和唤醒

#### Condition的使用

用于线程的暂停和继续。也就是挂起和唤醒

通常与锁（如 `Lock`或 `RLock`）一起使用，以实现线程间的同步和通信

创建Condition实例

```python3
cond=threading.Condition()
```

挂起线程

```python3
cond.wait()
```

唤醒线程

注意notify并不会主动释放锁

```python3
cond.notify()
```

使用案例：

```python
import threading
import time

# 共享资源
queue = []
# 创建一个Condition对象和一个锁对象
condition = threading.Condition()

def producer():
    global queue
    while True:
        with condition:
            item = "item"
            queue.append(item)
            print("Producer produced:", item)
            condition.notify()  # 通知消费者有新的项目可用
        time.sleep(1)

def consumer():
    global queue
    while True:
        with condition:
            while not queue:  # 当队列为空时，等待生产者生产项目
                condition.wait()
            item = queue.pop(0)
            print("Consumer consumed:", item)
        time.sleep(2)

# 创建生产者和消费者线程
producer_thread = threading.Thread(target=producer)
consumer_thread = threading.Thread(target=consumer)

# 启动线程
producer_thread.start()
consumer_thread.start()

# 等待线程执行完毕
producer_thread.join()
consumer_thread.join()
```

#### Event的使用

创建Event实例

```text
code=threading.Event()
```

使线程阻塞等待，Event未触发则wait会阻塞线程，知道Evnet对象被触发

```text
code.wait()
```

设置为已触发状态

```text
code.set()
```

1.  使用 `is_set()`方法检查 `Event`对象是否已触发。

```python
is_set = event.is_set()
```

设置为未触发状态

```text
code.clear()
```

案例：

```python
import threading
import time

# 创建一个Event对象
event = threading.Event()

def worker():
    print("Worker is waiting for event to be set")
    event.wait()  # 等待Event对象被触发
    print("Worker received event")

# 创建一个线程
worker_thread = threading.Thread(target=worker)

# 启动线程
worker_thread.start()

# 等待一段时间
time.sleep(2)

# 将Event对象设置为已触发状态
event.set()

# 等待线程执行完毕
worker_thread.join()
```

### 线程队列

先进先出队列（Queue）

后进先出队列（LifoQueue）

优先级队列（PriorityQueue）

#### 线程队列的常用方法

| 方法名        | 说明                                       |
| ------------- | ------------------------------------------ |
| get()         | 从队列中取出元素，队列中没有元素时阻塞等待 |
| put()         | 向队列中放入元素，队列满时，阻塞等待       |
| get\_nowait() | 从队列中取出元素，队列中没有元素时会报错   |
| put\_nowait() | 向队列中放入元素，队列满时会报错           |
| qsize()       | 返回当前队列中的元素                       |
| empty()       | 判断队列是否为空，返回布尔值               |
| full()        | 判断队列是否已满，返回布尔值               |
| task\_done()  | 每次item被处理的时候需要调用这个方法       |

#### Queue

提供了一个线程安全的队列类，在多个线程之间传递数据。

实现生产者-消费者模式，生产者写入数据，消费者取出数据。

```python
import threading
import queue
import time

# 创建一个Queue对象
q = queue.Queue()

defproducer():
for i inrange(5):
        item =f"item-{i}"
        q.put(item)
print(f"Producer produced: {item}")
        time.sleep(1)

defconsumer():
for i inrange(5):
        item = q.get()
print(f"Consumer consumed: {item}")
        time.sleep(2)

# 创建生产者和消费者线程
producer_thread = threading.Thread(target=producer)
consumer_thread = threading.Thread(target=consumer)

# 启动线程
producer_thread.start()
consumer_thread.start()

# 等待线程执行完毕
producer_thread.join()
consumer_thread.join()
```

#### LifoQueue

后进先出，堆模式

```python
import queue

# 创建一个LifoQueue对象
lifo_q = queue.LifoQueue()

# 将数据放入队列
lifo_q.put("item1")
lifo_q.put("item2")
lifo_q.put("item3")

# 从队列中取出数据
item1 = lifo_q.get()
item2 = lifo_q.get()
item3 = lifo_q.get()

print(item1)  # 输出：item3
print(item2)  # 输出：item2
print(item3)  # 输出：item1
```

#### PriorityQueue

写入设置优先级。

优先级：由于小到大，包含负数

```python
import queue

# 创建一个PriorityQueue对象
priority_q = queue.PriorityQueue()

# 将数据放入队列
priority_q.put((2, "item1"))
priority_q.put((1, "item2"))
priority_q.put((3, "item3"))

# 从队列中取出数据
item1 = priority_q.get()
item2 = priority_q.get()
item3 = priority_q.get()

print(item1)  # 输出：(1, 'item2')
print(item2)  # 输出：(2, 'item1')
print(item3)  # 输出：(3, 'item3')
```

### 线程池（pool）

导入对应的模块

```text
from concurrent.futures import ThreadPoolExecutor
```

创建线程池

```text
executor=ThreadPoolExecutor(max_workers=2)
# 参数max_workers 表示线程池中线程的最大数量
```

提交任务

```text
executor.submit(fn,*args,**kwargs)
#参数 fn是提交的任务名称，即方法名
#参数 args 表示fn的参数，元组
#参数 kwargs 表示fn参数，字典
```

ThreadPoolExecutor的常用方法

| 方法名称                                          |                                                              |
| ------------------------------------------------- | ------------------------------------------------------------ |
| submit(self, fn, \*args, \*\*kwargs)              | fn是提交的任务名称，args 表示fn的参数，元组。 kwargs 表示fn参数，字典。返回值是Future实例 |
| shutdown(self, wait=True)                         | 关闭线程池，等所有线程执行完毕，可以设置wait=False 让函数立即返回 |
| map(func, \*iterables, timeout=None, chunksize=1) | func表示提交的任务的名称，iterables为参数func，将从iterables遍历元素作为func的参数，timeout设置超时时间，返回值使用含有Future的列表 |

使用示例

```python
from concurrent.futures import ThreadPoolExecutor
import threading


def worker(num):

    for i in  range(num):
        print(f"当前的线程是：{threading.current_thread().name} 输出是：{i}")


def main():

   data=[(100,2),(100,3),(1000,3)]

   with ThreadPoolExecutor(max_workers=2) as executor:


       future_list=[executor.submit(worker,i) for i in [100,100,100]]


if __name__ == '__main__':
    main()
```

使用示例

```python
from concurrent.futures import ThreadPoolExecutor
import threading


def worker(num):
    for i in  range(num):
        print(f"当前的线程是：{threading.current_thread().name} 输出是：{i}")


def main():
    with ThreadPoolExecutor(max_workers=2) as executor:
       executor_map = executor.map(worker, [100,100,100,1000])
       print(executor_map)


if __name__ == '__main__':
    main()
```

map多个参数的处理

```python
import threading


def worker(num,w):

    for i in  range(num):
        print(f"当前的线程是：{threading.current_thread().name} 输出是：{i},{w}")


def main():

   data=[(100,2),(100,3),(1000,3)]

   with ThreadPoolExecutor(max_workers=2) as executor:
       executor_map = executor.map(worker, *zip(*data))

       print(executor_map)


if __name__ == '__main__':
    main()
```

Future的常用方法

| 方法名                  | 说明                                                         |
| ----------------------- | ------------------------------------------------------------ |
| cancel()                | 取消该Future代表的线程任务                                   |
| result(timeout=None)    | 获取该 Future 代表的线程任务最后返回的结果                   |
| add\_done\_callback(fn) | 为该 Future 代表的线程任务注册一个“回调函数”，当该任务成功完成时，程序会自动触发该 fn 函数 |
| done()                  | Future代表的线程任务被成功取消或执行完成，则该方法返回True   |

```python
import concurrent.futures
import time

def task():
    time.sleep(2)
    return "Task completed"

# 创建一个ThreadPoolExecutor对象
executor = concurrent.futures.ThreadPoolExecutor()

# 提交任务并获取Future对象
future = executor.submit(task)

# 检查任务是否完成
is_done = future.done()
print(f"Task is done: {is_done}")  # 输出：Task is done: False

# 获取任务结果
result = future.result()
print(f"Task result: {result}")  # 输出：Task result: Task completed

# 检查任务是否完成
is_done = future.done()
print(f"Task is done: {is_done}")  # 输出：Task is done: True

# 关闭线程池
executor.shutdown()
```

# 协程

asyncio模块

```python
import asyncio

async def my_async_function():
    print("Starting")
    await asyncio.sleep(2)
    print("Completed")

# python 3.7以下运行协程方法
loop = asyncio.get_event_loop()
loop.run_until_complete(my_async_function())
loop.close()

# python 3.7以上运行协程方法
asyncio.run(协程方法名())

```

## async关键字

定义协程函数

格式：

```python
async def 函数名:
      函数体
```

```python
# 协程函数
async def func():
    pass
# 协程对象
result = func()
```

此时协程函数不执行，必须要将协程对象交给事件循环来处理：

```python
import asyncio

async def my_async_function():
    print("Starting async function")
    await asyncio.sleep(2)
    print("Async function completed")

async def main():
    await my_async_function()

loop = asyncio.get_event_loop()
loop.run_until_complete(main())
loop.close()

```

```python
import aiohttp
import asyncio

# 常见的http请求的io性能优化

async def download_page(url):
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            content = await response.text()
            print(f"Downloaded {url}")
            return content

async def main():
    urls = [
        "https://www.example.com",
        "https://www.example.org",
        "https://www.example.net",
    ]

    # 使用asyncio.gather()等待所有协程完成
    await asyncio.gather(*[download_page(url) for url in urls])

loop = asyncio.get_event_loop()
loop.run_until_complete(main())
loop.close()
```

运行多个协程：

```python
import asyncio

async def task1():
    print("Task 1 started")
    await asyncio.sleep(2)
    print("Task 1 completed")

async def task2():
    print("Task 2 started")
    await asyncio.sleep(1)
    print("Task 2 completed")

async def task3():
    print("Task 3 started")
    await asyncio.sleep(3)
    print("Task 3 completed")

async def main():
    # 同时运行多个任务
    await asyncio.gather(task1(), task2(), task3())

loop = asyncio.get_event_loop()
loop.run_until_complete(main())
loop.close()


```

调用多个协程：

```python
import asyncio

async def task1():
    print("Task 1 started")
    await asyncio.sleep(2)
    print("Task 1 completed")
    return "Result from Task 1"

async def task2():
    print("Task 2 started")
    await asyncio.sleep(1)
    print("Task 2 completed")
    return "Result from Task 2"

async def main():
    # 创建任务
task_1 = asyncio.ensure_future(task1())
    task_2 = asyncio.ensure_future(task2())

    # 同时运行多个任务，并等待它们全部完成
results = await asyncio.gather(task_1, task_2)

    # 获取每个任务的返回值
result_1, result_2 = results
    print("Result from Task 1:", result_1)
    print("Result from Task 2:", result_2)

# 创建事件循环并运行主程序
loop = asyncio.get_event_loop()
loop.run_until_complete(main())
loop.close()
```

## **await 关键字**

await + 可等待的对象（协程对象、Future、Task对象 、IO等待），当遇到await时，会挂起当前的协程，去事件循环队列执行其他的协程，当可等待对象有操作完成时，再执行await后面的代码。

```python
import asyncio

async def others():
    print("start")
    await asyncio.sleep(2)
    print('end')
    return '返回值'

async def func():
    print("执行协程函数内部代码")
    # await等待对象的值得到结果之后再继续向下走
    response = await others()
    print("IO请求结束，结果为：", response)
  
loop = asyncio.get_event_loop()
loop.run_until_complete(func())
loop.close()
```

### **Task 对象**

Task对象的作用是在事件循环中添加多个任务，用于并发调度协程

```python
import asyncio

async def module_a():
    print("start module_a")
    await asyncio.sleep(2) # 模拟 module_a 的io操作
    print('end module_a')
    return 'module_a 完成'

async def module_b():
    print("start module_b")
    await asyncio.sleep(1) # 模拟 module_a 的io操作
    print('end module_b')
    return 'module_b 完成'

task_list = [
    module_a(),
    module_b(),
]

loop = asyncio.get_event_loop()
done,pending =loop.run_until_complete(asyncio.wait(task_list))
print(done)


async def module_a():
    print("start module_a")
    await asyncio.sleep(2) # 模拟 module_a 的io操作
    print('end module_a')
    return 'module_a 完成'

async def module_b():
    print("start module_b")
    await asyncio.sleep(1) # 模拟 module_a 的io操作
    print('end module_b')
    return 'module_b 完成'

task_list = [
    module_a(),
    module_b(),
]

done,pending =loop.run_until_complete(asyncio.wait(task_list))
print(done)
loop.close()
```

## run\_until\_complete

它用于运行一个协程

```python
import asyncio

async def my_async_function():
    print("Starting")
    await asyncio.sleep(2)
    print("Completed")

loop = asyncio.get_event_loop()
loop.run_until_complete(my_async_function())
loop.close()
```

# 进程

## 创建进程

使用函数的方式创建多进程

```python
import multiprocessing
import time

def foo(name):
    time.sleep(1)
    print('hello', name, time.time())

def my_function(x):
    print(f"Process {multiprocessing.current_process().name} is running with argument {x}")

if __name__ == "__main__":
    # 进程的创建和运行必须有main启动函数去触发，不能没有主线程直接调用
    process = multiprocessing.Process(target=my_function, args=(42,))
    process.start()
    process.join()
  
    p = multiprocessing.Process(target=foo, args=('张三',))
    p.start()
    p.join()

```

使用类创建多进程

```python

from multiprocessing import Process

import time

class MyProcess(Process):
    def __init__(self):
        super().__init__(name='进程')

    def run(self):
        time.sleep(1)
        print('hello', self.name, self.pid, self.is_alive(), time.ctime())


if __name__ == '__main__':
    process_list = []
    for i in range(5):
        p = MyProcess()
        process_list.append(p)
        p.start()

    for i in process_list:
        i.join()

    print('结束进程')

```

## 进程池

```python
import multiprocessing
import time
def get_html(n):
    print('副进程中:', n)
    time.sleep(10)
    return 'http://www.baidu.com/{}'.format(n)

if __name__ == "__main__":
    # 创建一个进程池,如果里面没写值就会默认你CPU的多少
    pool = multiprocessing.Pool(multiprocessing.cpu_count())
    result = pool.apply_async(get_html, args=(1,))
    pool.close()
    pool.join()
    print('主进程中:', result.get())
```

# concurrent.futures库的使用

## 创建线程池

```python
from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor



def fn(i):
    print("我是线程"+str(i))
    return i

# 回调函数
def  fn1(e):

    print(e.result())
    print("我是回调函数")



if __name__ == '__main__':

    # 创建进程池
    with ThreadPoolExecutor() as threapool:

        # 批量提交任务
        lis =[]
        for i in range(10):
            lis.append(threapool.submit(fn,i))

        for i in lis:
            i.add_done_callback(fn1)

        # 获取返回结果
        for i in lis:
            i.result()
```

## 创建进程池

```python
from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor,as_completed
import time

def my_function(x):
    print(f"Process {x} started")
    time.sleep(2)
    print(f"Process {x} completed")
    return x * 2

def callback(future):
    print(f"Callback: Result of process {future.result() // 2} is {future.result()}")

if __name__ == "__main__":
    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(my_function, i) for i in range(10)]

        for future in as_completed(futures):
            future.add_done_callback(callback)
```